# -*- coding: utf-8 -*-
"""Sus_AI_Capstone.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HOfnumxkpUJ7Q_9PH7ERCrfXyM6YZytG

#Project Topic: AI-driven market access platforms connecting farmers directly to buyers, predicting market prices and optimizing crop sales.

##Team Members: Ved, Eeshan and Shubham
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

file_path = "Dataset.csv"
df = pd.read_csv(file_path)

print("Dataset shape:", df.shape)
print("\nFirst 5 rows:")
print(df.head())

print("\nDataset info:")
print(df.info())

print("\nMissing values per column:")
print(df.isnull().sum())

#Clean column names
df.rename(columns={
    "Min_x0020_Price": "Min_Price",
    "Max_x0020_Price": "Max_Price",
    "Modal_x0020_Price": "Modal_Price"
}, inplace=True)

#Convert Arrival_Date to datetime
df["Arrival_Date"] = pd.to_datetime(df["Arrival_Date"], errors="coerce")

#Remove duplicates (if any)
before = df.shape[0]
df.drop_duplicates(inplace=True)
after = df.shape[0]

print(f"Removed {before - after} duplicate rows")

#Strip spaces from text columns
for col in df.select_dtypes(include="object").columns:
    df[col] = df[col].str.strip()

# Final check
print("\nCleaned dataset info:")
print(df.info())
print("\nSample rows after cleaning:")
print(df.head())

#Price Distribution (Min, Max, Modal)
plt.figure(figsize=(8,5))
sns.boxplot(data=df[["Min_Price","Max_Price","Modal_Price"]])
plt.title("Price Distribution (Min, Max, Modal)")
plt.ylabel("Price")
plt.show()

#Commodity Frequency (Top 10 Commodities)
plt.figure(figsize=(10,6))
df["Commodity"].value_counts().head(10).plot(kind="bar", color="skyblue")
plt.title("Top 10 Commodities by Frequency")
plt.xlabel("Commodity")
plt.ylabel("Count")
plt.xticks(rotation=45)
plt.show()

#Average Modal Price by Commodity (Top 10)
plt.figure(figsize=(12,6))
avg_price = df.groupby("Commodity")["Modal_Price"].mean().sort_values(ascending=False).head(10)
sns.barplot(x=avg_price.index, y=avg_price.values, palette="viridis")
plt.title("Top 10 Commodities by Average Modal Price")
plt.ylabel("Average Modal Price")
plt.xlabel("Commodity")
plt.xticks(rotation=45)
plt.show()

#Trends Over Time (Modal Price)
plt.figure(figsize=(12,6))
df.groupby("Arrival_Date")["Modal_Price"].mean().plot()
plt.title("Trend of Average Modal Price Over Time")
plt.xlabel("Date")
plt.ylabel("Average Modal Price")
plt.grid(True)
plt.show()

#State-wise Average Price
plt.figure(figsize=(12,6))
state_prices = df.groupby("State")["Modal_Price"].mean().sort_values(ascending=False)
sns.barplot(x=state_prices.index, y=state_prices.values, palette="magma")
plt.title("Average Modal Price by State")
plt.xticks(rotation=90)
plt.ylabel("Average Modal Price")
plt.show()

#Correlation Between Prices
plt.figure(figsize=(6,4))
sns.heatmap(df[["Min_Price","Max_Price","Modal_Price"]].corr(), annot=True, cmap="coolwarm")
plt.title("Correlation Between Price Columns")
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.linear_model import LinearRegression
import numpy as np

# Copy dataset
data = df.copy()

# Extract date features
data["Year"] = data["Arrival_Date"].dt.year
data["Month"] = data["Arrival_Date"].dt.month
data["Day"] = data["Arrival_Date"].dt.day
data["Weekday"] = data["Arrival_Date"].dt.weekday

# Encode categorical columns
cat_cols = ["State","District","Market","Commodity","Variety","Grade"]
le = LabelEncoder()
for col in cat_cols:
    data[col] = le.fit_transform(data[col])

# Define features & target
X = data.drop(columns=["Modal_Price","Arrival_Date"])  # keep Min/Max as features
y = data["Modal_Price"]

# Sort by date first
data = data.sort_values("Arrival_Date")

# 80-20 split by index
split_idx = int(len(data) * 0.8)
train, test = data.iloc[:split_idx], data.iloc[split_idx:]

X_train, y_train = train.drop(columns=["Modal_Price","Arrival_Date"]), train["Modal_Price"]
X_test, y_test   = test.drop(columns=["Modal_Price","Arrival_Date"]), test["Modal_Price"]

print("Train size:", X_train.shape, " Test size:", X_test.shape)

# Baseline Linear Regression
lr = LinearRegression()
lr.fit(X_train, y_train)
y_pred = lr.predict(X_test)

# Evaluation
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f"Linear Regression Performance:")
print(f"MAE: {mae:.2f}")
print(f"RMSE: {rmse:.2f}")
print(f"R²: {r2:.2f}")

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
import pandas as pd

# --- Train-Test Split (time-aware) ---
data = data.sort_values("Arrival_Date")  # ensure chronological order
split_idx = int(len(data) * 0.8)
train, test = data.iloc[:split_idx], data.iloc[split_idx:]

X_train, y_train = train.drop(columns=["Modal_Price","Arrival_Date"]), train["Modal_Price"]
X_test, y_test   = test.drop(columns=["Modal_Price","Arrival_Date"]), test["Modal_Price"]

print("Train size:", X_train.shape, " Test size:", X_test.shape)

# --- Define models ---
models = {
    "Linear Regression": LinearRegression(),
    "Random Forest": RandomForestRegressor(n_estimators=200, random_state=42),
    "XGBoost": XGBRegressor(n_estimators=200, learning_rate=0.1, random_state=42)
}

# --- Train & Evaluate ---
results = []
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)

    results.append({"Model": name, "MAE": mae, "RMSE": rmse, "R²": r2})

# --- Results as DataFrame ---
results_df = pd.DataFrame(results)
print("\nModel Comparison Results:")
print(results_df)

# --- Bar Plot of Performance ---
import matplotlib.pyplot as plt

results_df.set_index("Model")[["MAE","RMSE"]].plot(kind="bar", figsize=(8,6))
plt.title("Model Error Comparison (Lower is Better)")
plt.ylabel("Error")
plt.xticks(rotation=0)
plt.show()

results_df.set_index("Model")["R²"].plot(kind="bar", figsize=(6,4), color="skyblue")
plt.title("Model R² Comparison (Higher is Better)")
plt.ylabel("R² Score")
plt.xticks(rotation=0)
plt.show()

import joblib

# Save models
joblib.dump(lr, "linear.pkl")
joblib.dump(models["Random Forest"], "rf.pkl")
joblib.dump(models["XGBoost"], "xgb.pkl")

# Save encoders (the LabelEncoder objects you used)
encoders = {}
cat_cols = ["State","District","Market","Commodity","Variety","Grade"]
for col in cat_cols:
    le = LabelEncoder()
    le.fit(df[col])  # fit on full dataset
    encoders[col] = le

joblib.dump(encoders, "encoders.pkl")

# Save model evaluation results
results_df.to_csv("model_metrics.csv", index=False)
